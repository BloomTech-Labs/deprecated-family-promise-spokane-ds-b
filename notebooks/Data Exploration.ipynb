{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'joblib' from 'sklearn.externals' (/home/tyler/.local/share/virtualenvs/family-promise-spokane-ds-a-lmm-C0CO/lib/python3.8/site-packages/sklearn/externals/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-7f8a8b489270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'joblib' from 'sklearn.externals' (/home/tyler/.local/share/virtualenvs/family-promise-spokane-ds-a-lmm-C0CO/lib/python3.8/site-packages/sklearn/externals/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../All_data_with_exits.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Recategorization\n",
    "\n",
    "\n",
    "Because the target is initially recorded in a very granular manner, the target labels will need to be recategorized to fit into the 5 Categories provided by stakeholder:\n",
    "\n",
    "- Permanent Exit\n",
    "- Temporary Exit\n",
    "- Emergency Shelter\n",
    "- Transitional Housing\n",
    "- Unknown/Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Permanent Exit**\n",
    "\n",
    "- Staying or living with family, permanent tenure\n",
    "- Staying or living with friends, permanent tenure\n",
    "- Permanent housing (other than RRH) for formerly homeless persons\n",
    "- Rental by client with RRH or equivalent subsidy\n",
    "- Rental by client, no ongoing housing subsidy\n",
    "- Rental by client, other ongoing housing subsidy\n",
    "- Owned by client, no ongoing housing subsidy\n",
    "\n",
    "**Temporary Exit**  \n",
    "\n",
    "- Place not meant for habitation (e.g., a vehicle, an abandoned building, bus/train/subway station/airport or anywhere outside)\n",
    "- Staying or living with family, temporary tenure (e.g., room, apartment or house)\n",
    "- Staying or living with friends, temporary tenure (e.g., room, apartment or house)\n",
    "- Hotel or Motel paid for without Emergency Shelter Voucher\n",
    "\n",
    "**Emergency Shelter**  \n",
    "\n",
    "- Emergency shelter, including hotel or motel paid for with emergency shelter voucher, or RHY-funded Host Home shelter \n",
    "\n",
    "**Transitional Housing**  \n",
    "\n",
    "- Transitional Housing for homeless persons (including homeless youth)\n",
    "- Safe Haven\n",
    "- Substance Abuse Treatment or Detox Center\n",
    "- Foster Care Home or Foster Care Group Home\n",
    "- Psychiatric Hospital or Other Psychiatric Facility\n",
    "\n",
    "**Unknown/Other**\n",
    "\n",
    "- No exit interview completed\n",
    "- Client refused\n",
    "- Other\n",
    "- Client doesn't know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because pandas has a built in value mapping function that is more performant and consistent using a dictionary of this format, we are going with this dictionary structure rather than a more DRY dictionary with each entry as an element of a list with the category as the key.  \n",
    "e.g. `values_dict = {'Permanent Exit' : [some_value, some_value2]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use apply to assign values in dataframe to categories\n",
    "values_dict = {\n",
    "    # Permanent Exits\n",
    "    'Staying or living with family, permanent tenure' : 'Permanent Exit',\n",
    "    'Staying or living with friends, permanent tenure' : 'Permanent Exit',\n",
    "    'Permanent housing (other than RRH) for formerly homeless persons' : 'Permanent Exit',\n",
    "    'Rental by client with RRH or equivalent subsidy' : 'Permanent Exit',\n",
    "    'Rental by client, no ongoing housing subsidy' : 'Permanent Exit',\n",
    "    'Rental by client, other ongoing housing subsidy' : 'Permanent Exit',\n",
    "    'Owned by client, no ongoing housing subsidy' : 'Permanent Exit',\n",
    "    # Temporary Exits\n",
    "    'Staying or living with family, temporary tenure (e.g., room, apartment or house)' : 'Temporary Exit',\n",
    "    'Staying or living with friends, temporary tenure (e.g., room, apartment or house)' : 'Temporary Exit',\n",
    "    'Hotel or Motel paid for without Emergency Shelter Voucher' : 'Temporary Exit',\n",
    "    # Emergency Shelter\n",
    "    'Emergency shelter, including hotel or motel paid for with emergency shelter voucher, or RHY-funded Host Home shelter' : 'Emergency Shelter',\n",
    "    # Transitional Housing\n",
    "    'Transitional Housing for homeless persons (including homeless youth)' : 'Transitional Housing',\n",
    "    'Safe Haven' : 'Transitional Housing',\n",
    "    'Substance Abuse Treatment or Detox Center' : 'Transitional Housing',\n",
    "    'Foster Care Home or Foster Care Group Home' : 'Transitional Housing',\n",
    "    'Psychiatric Hospital or Other Psychiatric Facility' : 'Transitional Housing',\n",
    "    # Unknown/Other\n",
    "    'Place not meant for habitation (e.g., a vehicle, an abandoned building, bus/train/subway station/airport or anywhere outside)' : 'Unknown/Other',\n",
    "    'No exit interview completed' : 'Unknown/Other',\n",
    "    'Client refused' : 'Unknown/Other',\n",
    "    'Other' : 'Unknown/Other',\n",
    "    'Client doesn\\'t know' : 'Unknown/Other',\n",
    "    np.NaN : 'Unknown/Other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that need to have dtype converted to datetime\n",
    "date_features = ['Enroll Date', 'Exit Date', 'CurrentDate', 'Date of First Contact (Beta)', \n",
    "                 'Date of First ES Stay (Beta)', 'Date of Last Contact (Beta)', \n",
    "                 'Date of Last ES Stay (Beta)', 'Engagement Date','Homeless Start Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features will artifacts remaining after filter application to text\n",
    "text_artifacts = ['RReferral Source',\n",
    "                  'RDate Status Determined',\n",
    "                  'REnroll Status',\n",
    "                  'RRunaway Youth',\n",
    "                  'RReason Why No Services Funded',\n",
    "                  'RSexual Orientation',\n",
    "                  'RLast Grade Completed',\n",
    "                  'RSchool Status',\n",
    "                  'REmployed Status',\n",
    "                  'RWhy Not Employed',\n",
    "                  'RType of Employment',\n",
    "                  'RLooking for Work',\n",
    "                  'RGeneral Health Status',\n",
    "                  'RDental Health Status',\n",
    "                  'RMental Health Status',\n",
    "                  'RPregnancy Status',\n",
    "                  'RPregnancy Due Date',\n",
    "                  'VLast Permanent Address',\n",
    "                  'VState',\n",
    "                  'VZip']\n",
    "\n",
    "# Dict comprehension to generate dict of fixed names\n",
    "rename_dict = {k: k[1:] for k in text_artifacts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary used to impute data on dataframe\n",
    "# List of columns that needs values consolidated and imputed into \"Unknown\" value\n",
    "column_impute_list = ['Race' , 'Ethnicity' , 'Length of Stay']\n",
    "replace_list = ['Client refused','Client doesn\\'t know', 'Data not collected', np.NaN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline(dataf):\n",
    "    '''Creates a copy of original dataframe to use in pipeline'''\n",
    "    return dataf.copy()\n",
    "\n",
    "def column_cleaner(dataf):\n",
    "    '''Takes in a dataframe and removes decimals from column names'''\n",
    "    dataf.columns = dataf.columns.str.replace(r'\\d+.', '')\n",
    "    return dataf\n",
    "\n",
    "def column_rename(dataf):\n",
    "    '''Fixes column name artifacts from string filter'''\n",
    "    dataf = dataf.rename(columns = rename_dict)\n",
    "    return dataf\n",
    "\n",
    "def column_strip(dataf):\n",
    "    '''Strips leading whitespace artifacting from RE'''\n",
    "    dataf.columns = dataf.columns.str.lstrip(' ')\n",
    "    return dataf\n",
    "\n",
    "def set_dtypes(dataf):\n",
    "    '''Sets Data Type to specific columns'''\n",
    "    dataf[date_features] = dataf[date_features].apply(pd.to_datetime, infer_datetime_format=True)\n",
    "    return dataf\n",
    "\n",
    "def add_categories(dataf):\n",
    "    '''Adds each entry to one of the five target categories'''\n",
    "    dataf['Recategorized'] = dataf['Exit Destination'].map(values_dict)\n",
    "    return dataf\n",
    "\n",
    "def impute_values(dataf):\n",
    "    '''Takes columns in column_impute_list and replaces missing and unknown \n",
    "    values with \"Unknown\"'''\n",
    "    for column in column_impute_list:\n",
    "        dataf[column].replace(replace_list, 'Unknown', inplace=True)\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (df\n",
    "    .pipe(start_pipeline)\n",
    "    .pipe(column_cleaner)\n",
    "    .pipe(column_rename)\n",
    "    .pipe(column_strip)\n",
    "    .pipe(set_dtypes)\n",
    "    .pipe(add_categories)\n",
    "    .pipe(impute_values)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Results Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for enforcement of datetime dtype\n",
    "for column in date_features:\n",
    "    print(df2[column].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Recategorized'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Visualizations  \n",
    "\n",
    "Final Visualizations will need to be formatted with proper object usage and syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Distribution\n",
    "df2['Recategorized'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic scatterplots\n",
    "sns.scatterplot(data=df2, y='Recategorized', x='Income Total at Entry').set_title('Exit Destination vs. Income Total at Entry');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of Stay\n",
    "# Exit Date - Enroll Date\n",
    "df2['Enrollment Length'] = df2['Exit Date'] - df2['Enroll Date']\n",
    "print(df2['Enrollment Length'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['CaseMembers','Race', 'Ethnicity', \n",
    "            'Current Age', 'Gender', 'Length of Stay', \n",
    "            'Days Enrolled in Project','Household Type', \n",
    "            'Barrier Count at Entry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Recategorized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[features]\n",
    "y = df2[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate X and Y dfs\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Barrier Count at Entry'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Race'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test, Validation Split\n",
    "\n",
    "# First split : Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split : Train, Val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Modeling Strategy: \n",
    "- Implement SKL pipeline to add modularity to workflow\n",
    "- Begin with random forest implementation\n",
    "- Update model choices using combinations of cross-validation, loss metrics, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for random forest model\n",
    "random_forest_model = Pipeline([('ord', OrdinalEncoder()),\n",
    "                                ('imputer', SimpleImputer()),\n",
    "                                ('classifier', RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=42, verbose=1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "random_forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for classification report metrics\n",
    "y_true = y_val\n",
    "y_pred = random_forest_model.predict(X_val)\n",
    "target_names = ['Permanent Exit', 'Temporary Exit', 'Transitional Housing', 'Emergency Shelter' , 'Unknown/Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Serialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the classifier step from the pipeline\n",
    "clf = random_forest_model['classifier']\n",
    "joblib_file = \"randomforest_modelv1.pkl\"\n",
    "joblib.dump(clf, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
